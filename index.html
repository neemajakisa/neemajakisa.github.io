<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Neema Jakisa</title>

    <meta name="author" content="Neema Jakisa">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>


  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Neema Jakisa Owor
                </p>
                <p>
		I'm a post doctoral research associate at <a href="https://eng.umd.edu/">University of Maryland</a> applying multimodal and GenAI models to rail transportation. 
    <p style="text-align: justify;">My research focuses on integrating artificial intelligence (AI) and data-driven approaches to address critical challenges in
transportation systems, including design, infrastructure resilience, safety, and efficiency. By leveraging advanced AI techniques
such as computer vision, machine learning, and large language models (LLMs), I develop innovative solutions to enhance
decision-making, optimize resource allocation, and improve the performance of transportation networks, particularly in areas
like intersections, traffic control, and vulnerable road user safety.</p>
 <p style="text-align: justify;">My expertise in image analysis, computer vision, Large Language Models(LLMs) and predictive modeling has been applied to pavement condition assessment, work zone safety, and transportation data
analytics, with real-world implementations at the Missouri Department of Transportation (MoDOT).</p>
		<p style="text-align: justify;">I recieved my PhD at <a href="https://engineering.missouri.edu/">University of Missouri-Columbia</a>, where I was advised by <a href="https://engineering.missouri.edu/faculty/yaw-adu-gyamfi/">Yaw Adu-Gyamfi</a></p>
                </p>
                <p style="text-align:center">
                  <a href="mailto:njakisa@umd.edu">Work Email</a> &nbsp;/&nbsp; 
                  <a href="mailto:neemajakisa@gmail.com">Personal Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; #add CV later -->
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;-->
                  <a href="https://scholar.google.com/citations?user=-Tc3k9sAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/neema-jakisa-978753143/">LinkedIn</a> &nbsp;
                  <!--<a href="https://github.com/jonbarron/">Github</a> -->
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/Neema.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%; transform: rotate(40deg); " alt="profile photo" src="images/Neema.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">

                <h2>News</h2>
                    <ul style="list-style-type: none; padding-left: 0;">
                      <li style="margin-bottom: 15px; padding-left: 20px; border-left: 3px solid #007bff;">
                        <strong style="color: #007bff;">10/14/2025</strong> ‚Äî An LLM-Enhanced Framework for Comprehensive Traffic Sign Condition Assessment Integrating Daytime Visual Performance and Nighttime Retroreflectivity Evaluation has been accepted for presentation at <a href="https://trb-annual-meeting.nationalacademies.org/">Transportation Research Board Annual Meeting (TRBAM)</a>, 2026
                      </li>
                      <li style="margin-bottom: 15px; padding-left: 20px; border-left: 3px solid #007bff;">
                        <strong style="color: #007bff;">9/26/2025</strong> ‚Äî Multi-Modal Deep Learning Approach for Comprehensive Pavement Condition Evaluation Using Vision-Language Models has been accepted for both presentation and publication at <a href="https://trb-annual-meeting.nationalacademies.org/">TRBAM</a> and Transportation Research Record 2026
                      </li>
                      <li style="margin-bottom: 15px; padding-left: 20px; border-left: 3px solid #007bff;">
                        <strong style="color: #007bff;">9/26/2025</strong> ‚Äî A Generative AI-based Traffic Surveillance System Using Large Language Models (LLMs) has been accepted for presentation at <a href="https://trb-annual-meeting.nationalacademies.org">TRBAM</a>, 2026
                      </li>
                      <li style="margin-bottom: 15px; padding-left: 20px; border-left: 3px solid #007bff;">
                        <strong style="color: #007bff;">9/23/2025</strong> ‚Äî A Multi-Agent Framework for LLM-Based Transportation Data Analysis has been accepted for presentation at <a href="https://trb-annual-meeting.nationalacademies.org/">TRBAM</a>, 2026
                      </li>
                      <li style="margin-bottom: 15px; padding-left: 20px; border-left: 3px solid #28a745;">
                        <strong style="color: #28a745;">07/13/2025</strong> ‚Äî üèÜ Rank 10th of Track 2 in the <a href="https://www.aicitychallenge.org/"> AI City Challenge</a> in <a href="https://iccv.thecvf.com/">ICCV 2025</a>, organized by Nvidia
                      </li>
                      <li style="margin-bottom: 15px; padding-left: 20px; border-left: 3px solid #28a745;">
                        <strong style="color: #28a745;">07/13/2025</strong> ‚Äî üèÜ Rank 4th in Track 3 in the <a href="https://www.aicitychallenge.org/"> AI City Challenge</a> in <a href="https://iccv.thecvf.com/">ICCV 2025</a>, organized by Nvidia
                      </li>
                      <li style="margin-bottom: 15px; padding-left: 20px; border-left: 3px solid #28a745;">
                        <strong style="color: #28a745;">07/13/2025</strong> ‚Äî üèÜ Rank 8th in Track 4 in the <a href="https://www.aicitychallenge.org/">  AI City Challenge</a> in<a href="https://iccv.thecvf.com/">ICCV 2025</a>, organized by Nvidia
                      </li>
                      <li style="margin-bottom: 15px; padding-left: 20px; border-left: 3px solid #dc3545;">
                        <strong style="color: #dc3545;">07/13/2025</strong> ‚Äî Three papers accepted in <a href="https://iccv.thecvf.com/">IEEE/CVF International Conference on Computer Vision</a>
                      </li>
                    </ul>

                    <h2>Teaching</h2>
                    <p style="font-weight: bold; color: #333; margin-bottom: 10px;">University of Missouri-Columbia</p>
                    <ul style="list-style-type: none; padding-left: 0;">
                      <li style="margin-bottom: 12px; padding-left: 25px; position: relative;">
                        <span style="position: absolute; left: 0; color: #007bff;">üìö</span>
                        <strong>Spring 2023:</strong> Instructor for CV_ENG 3100: Fundamentals of Transportation Engineering Lab
                      </li>
                      <li style="margin-bottom: 12px; padding-left: 25px; position: relative;">
                        <span style="position: absolute; left: 0; color: #007bff;">üìö</span>
                        <strong>Fall 2023:</strong> Instructor for CV_ENG 3100: Fundamentals of Transportation Engineering Lab
                      </li>
                      <li style="margin-bottom: 12px; padding-left: 25px; position: relative;">
                        <span style="position: absolute; left: 0; color: #007bff;">üìö</span>
                        <strong>Spring 2024:</strong> Instructor for CV_ENG 3100: Fundamentals of Transportation Engineering Lab
                      </li>
                      <li style="margin-bottom: 12px; padding-left: 25px; position: relative;">
                        <span style="position: absolute; left: 0; color: #28a745;">üéì</span>
                        <strong>Fall 2024:</strong> Teaching Assistant for CV_ENG 7001: Urban Transportation Data Science
                      </li>
                    </ul>
    
              
              
                <h2 strong>Publications</h2 strong>
               
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="image-container">
          <img src="images/Fisheye.png" width="180" height="140" class="pop-image">
        </div>
      </td>   
    
    <style>
      .image-container {
        display: inline-block;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
      }
      
      .pop-image {
        border-radius: 8px;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
      }
      
      .image-container:hover .pop-image {
        transform: scale(3); /* makes it "pop out" */
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3); /* soft shadow */
        z-index: 10;
      }
      </style>


      <td style="padding:8px;width:80%;vertical-align:middle">
        <a>
          <span class="papertitle">A Unified Detection Pipeline for Robust Object Detection in Fisheye-Base Traffic Surveillance</span>
        </a>
        <br>
        <strong>Neema Jakisa Owor</strong>,
        Joshua Kofi Asamoah,
        Tanner Wambui Muturi,
        Anneliese Jakisa Owor,
        Blessing Agyei Kyem,
        Andrews Danyo
        Yaw Adu-Gyamf,
		    Armstrong Aboah,
        <br>
        <em>IEEE/CVF International Conference on Computer Vision(ICCV) </em>, 2025
        <br>
        <a href="https://openaccess.thecvf.com/content/ICCV2025W/AICity/papers/Owor_A_Unified_Detection_Pipeline_for_Robust_Object_Detection_in_Fisheye-Based_ICCVW_2025_paper.pdf">paper</a>
        <p></p>
        <p>
		This approach presents a detection framework that can robustly detect traffic objects robustly with a simple yet effective pre and post processing pipeline especially in regions affected by distortion.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="image-container">
          <img src="images/videollama_qwen2.5.png" width="180" class="pop-image">
        </div>
      </td> 
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a>
			<span class="papertitle">Task-specific dual-model framework for comprehensive traffic safety video description and analysis.
</span>
        </a>
        <br>
				Blessing Agyei Kyem, 
				<strong>Neema Jakisa Owor</strong>,
				Andrews Danyo,
        Joshua K Asamoah,
        Eugene Denteh,
        Tanner Muturi,
        Anthony Dontoh,
				Yaw Adu-Gyamfi
        Armstrong Aboah
				<br>
        <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2025 
        <br>
        <a href="https://openaccess.thecvf.com/content/ICCV2025W/AICity/papers/Kyem_Task-Specific_Dual-Model_Framework_for_Comprehensive_Traffic_Safety_Video_Description_and_ICCVW_2025_paper.pdf">paper</a>
        <p></p>
        <p>
				A unique dual-model framework is developed that strategically utilizes complementary strengths of VideoLLaMA and Qwen2.5-VL through task-specfic optimization.
        </p>
      </td>
    </tr>



      <tr>
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="image-container">
            <img src="images/prompt.png" width="180" class="pop-image">
          </div>
        </td> 
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a>
			<span class="papertitle">Prompt-guided spatial understanding with RGB-D transformers for fine-grained object relation reasoning
</span>
        </a>
        <br>
        Tanner W Muturi,
        Blesssing Agyei Kyem,
        Joshua Kofi Asamoah,
				<strong>Neema Jakisa Owor</strong>,
				Richard Dzinyela,
        Andrews Danyo,
        Yaw Adu-Gyamfi,
        Armstrong Aboah
        <br>
        <em>IEEE/CVF International Conference on Computer Vision(ICCV)</em>, 2025 
        <br>
        <a href="https://openaccess.thecvf.com/content/ICCV2025W/AICity/papers/Muturi_Prompt-Guided_Spatial_Understanding_with_RGB-D_Transformers_for_Fine-Grained_Object_Relation_ICCVW_2025_paper.pdf">paper</a>
        <p></p>
        <p>
			A spatial intelligent framework was developed to enhance the spatial comprehension by embedding bounding box coordinates and object mask dimensions directly into the input prompt.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="image-container">
          <img src="images/Optimize_distress.png" width="180" class="pop-image">
        </div>
      </td> 
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a>
          <span class="papertitle">Optimizing Road amage Detection with YOLOv10: A Resorce-Efficient Approcah Utilizing Augmnetation, Data Sampling and Hyperparameter Tuning</span>
        </a>
        <br>
        Ashkan Behzadian,
        <strong>Neema Jakisa Owor</strong>,
				Tanner Muturi,
        Yaw Adu-Gyamfi
        <br>
        <em>IEEE International Conference on Big Data </em>, 2024
        <br>
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10825391">paper</a>
        <p></p>
        <p>
				We proposed an optimized approach using YOLOv10 model designed to balance detection accuracy and inference speed.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="image-container">
          <img src="images/PaveSAM.png" width="180" class="pop-image">
        </div>
      </td> 

      <td style="padding:8px;width:80%;vertical-align:middle">
        <a>
          <span class="papertitle">PaveSAM - Segment Anything for pavement distress</span>
        </a>
        <br>
        <strong>Neema Jakisa Owor</strong>,
        Yaw Adu-Gyamfi,
        Mark Amo-Boateng,
        Armstrong Aboah
        <br>
        <em>Road Materials and Pavement Design</em>, 2024
        <br>
        <a href="https://www.tandfonline.com/doi/abs/10.1080/14680629.2024.2374863">paper</a>
        /
        <a href="https://arxiv.org/pdf/2409.07295">arXiv</a>
        <p></p>
        <p>
          A zero-shot segmentation model, PaveSAM,is developed which can segment pavement distresses using bounding box prompts.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="image-container">
          <img src="images/AutoTMA.png" width="180" class="pop-image">
        </div>
      </td> 

      <td style="padding:8px;width:80%;vertical-align:middle">
        <a>
          <span class="papertitle">Automated Audible Truck-Mounted Attenuator Alerts: Vision System Development and Evaluation</span>
        </a>
        <br>
        <strong>Neema Jakisa Owor</strong>,
        Yaw Adu-Gyamfi,
        Linlin Zhang,
        Carlos Sun
        <br>
        <em>MDPI AI</em>, 2024
        <br>
        <a href="https://www.mdpi.com/2673-2688/5/4/90">paper</a>
        <p></p>
        <p>
          The system uses multi-task learning (MTL) to detect and classify vehicles, estimate distance zones (danger, warning, and safe), and perform lane and road segmentation. 
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="image-container">
          <img src="images/Image2PCI.png" width="180" class="pop-image">
        </div>
      </td> 

      <td style="padding:8px;width:80%;vertical-align:middle">
        <a>
          <span class="papertitle">Image2PCI - A Multitask Learning Framework for Estimating Pavement Condition Indices Directly from Images</span>
        </a>
        <br>
        <strong>Neema Jakisa Owor</strong>,
        Hang Du,
        Abdulateef Daud,
        Armstrong Aboah,
        Yaw Adu-Gyamfi
      </br>
      <br>
      <em>Transportation Research Board Annual Meeting</em>, 2023
      <br>
        <a href="https://arxiv.org/abs/2310.08538">paper</a>
        <p></p>
        <p>
          The proposed architecture is a multi-task model composed of one encoder for feature extraction and four decoders to handle specific tasks. By multitasking, we are able to extract features and estimate the PCI directly from the images.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="image-container">
          <img src="images/Edge.png" width="180" class="pop-image">
        </div>
      </td> 

      <td style="padding:8px;width:80%;vertical-align:middle">
        <a>
          <span class="papertitle">Edge Computing-Enabled Road Condition Monitoring: System Development and Evaluation</span>
        </a>
        <br>
        Abdulateef Daud,
        <strong>Neema Jakisa Owor</strong>,
        Mark Amo-Boateng,
        Yaw Adu-Gyamfi
      </br>
      <br>
      <em>Transportation Research Board Annual Meeting</em>, 2023
      <br>
        <a href="https://arxiv.org/pdf/2310.05321">paper</a>
        <p></p>
        <p>
          This study proposes a solution that uses a microcontroller mounted on axles of vehicles to analyze pavement condition data, in real-time.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="image-container">
          <img src="images/Deepsegmenter.png" width="180" class="pop-image">
        </div>
      </td> 

      <td style="padding:8px;width:80%;vertical-align:middle">
        <a>
          <span class="papertitle">Deepsegmenter: Temporal action localization for detecting anomalies in untrimmed naturalistic driving videos</span>
        </a>
        <br>
        Armstrong Aboah,
        <strong>Neema Jakisa Owor</strong>,
        Abdul Rashid Mussah
        Yaw Adu-Gyamfi
      </br>
      <br>
      <em>IEEE/CVF Conference on COmputer Vision and Pattern Recognition</em>, 2023
      <br>
        <a href="https://openaccess.thecvf.com/content/CVPR2023W/AICity/papers/Aboah_DeepSegmenter_Temporal_Action_Localization_for_Detecting_Anomalies_in_Untrimmed_Naturalistic_CVPRW_2023_paper.pdf">paper</a>
        <p></p>
        <p>
          The study introduces a novel methodological framework, DeepSegmenter, that simultaneously performs activity segmentation and classification in a naturalistic driving videos.
        </p>
      </td>
    </tr>



  

        </td>
      </tr>
    </table>
  </body>
</html>
